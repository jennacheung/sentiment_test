{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu number is : 4\n",
      "       tag                                                sen  \\\n",
      "0        0  It really boggles my mind when someone comes a...   \n",
      "1        0  Mary Pickford becomes the chieftain of a Scott...   \n",
      "2        0  Well, at least my theater group did, lol. So o...   \n",
      "3        1  I must give How She Move a near-perfect rating...   \n",
      "4        0  I must say, when I read the storyline on the b...   \n",
      "...    ...                                                ...   \n",
      "19995    1  Simple, meaningful and delivers an emotional p...   \n",
      "19996    1  I'm fan of ART, I like anything about Art, I l...   \n",
      "19997    0  Despite being a sequel to the more potent orig...   \n",
      "19998    0  Also known in a different form as \"House of Ex...   \n",
      "19999    0  This has the absolute worst performance from R...   \n",
      "\n",
      "                                                 cut_sen  \n",
      "0      [It, really, boggles, mind, someone, comes, ac...  \n",
      "1      [Mary, Pickford, becomes, chieftain, Scottish,...  \n",
      "2      [Well, least, theater, group, lol, So, course,...  \n",
      "3      [I, must, give, How, She, Move, near-perfect, ...  \n",
      "4      [I, must, say, I, read, storyline, back, case,...  \n",
      "...                                                  ...  \n",
      "19995  [Simple, meaningful, delivers, emotional, punc...  \n",
      "19996  [I, 'm, fan, ART, I, like, anything, Art, I, l...  \n",
      "19997  [Despite, sequel, potent, original, comical, r...  \n",
      "19998  [Also, known, different, form, ``, House, Exor...  \n",
      "19999  [This, absolute, worst, performance, Robert, D...  \n",
      "\n",
      "[20000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models import Doc2Vec\n",
    "from tqdm import tqdm\n",
    "from sklearn import utils\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "print(\"cpu number is :\", cores)\n",
    "\n",
    "\n",
    "# 第一步 数据预处理，\n",
    "def cut(document):\n",
    "    # 定义删除除字母,数字\n",
    "    doc = nltk.word_tokenize(document)\n",
    "    filtered = [w for w in doc if (w not in stopwords.words('english') and w not in '!@#$%^&*()_+<>?\":,./;{}[]')]\n",
    "    return filtered\n",
    "\n",
    "\n",
    "df_train = pd.read_csv('/Users/yuchk/PycharmProjects/IMDB/0_dataset/orign/train_imdb.tsv',\n",
    "                 usecols=['tag', 'sen'], sep='\\t')\n",
    "df_test = pd.read_csv('/Users/yuchk/PycharmProjects/IMDB/0_dataset/orign/test_imdb.tsv',\n",
    "                 usecols=['tag', 'sen'], sep='\\t')\n",
    "# 分词，并过滤停用词\n",
    "df_train['cut_sen'] = df_train['sen'].apply(cut)\n",
    "\n",
    "print(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18000/18000 [00:00<00:00, 2732742.32it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train, test = train_test_split(df_train, random_state=42, test_size = 0.1)\n",
    "# 创建标签化文档\n",
    "train_tagged = train.apply(\n",
    "    lambda r: TaggedDocument(words=r['cut_sen'], tags=[r['tag']]), axis=1)\n",
    "test_tagged = test.apply(\n",
    "    lambda r: TaggedDocument(words=r['cut_sen'], tags=[r['tag']]), axis=1)\n",
    "\n",
    "model_dbow = Doc2Vec(dm=0, negative=5, hs=0, min_count=2, workers=cores)\n",
    "model_dbow.build_vocab([x for x in tqdm(train_tagged.values)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18000/18000 [00:00<00:00, 1519797.73it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dbow.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values),\n",
    "                     epochs=10)\n",
    "model_dbow.alpha -= 0.002\n",
    "model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_for_learning(model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
    "    return targets, regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, X_train = vec_for_learning(model_dbow, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow, test_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### 使用逻辑回归来预测###########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.896\n",
      "Testing F1 score: 0.8959999999999999\n",
      "#############向量机################\n",
      "Testing accuracy 0.892\n",
      "Testing F1 score: 0.8919999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "print(\"############### 使用逻辑回归来预测###########\")\n",
    "log_reg = LogisticRegression(n_jobs=cores, C=1e5, solver='liblinear', max_iter=10000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred = log_reg.predict(X_test)\n",
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))\n",
    "\n",
    "print(\"#############向量机################\")\n",
    "modell = LinearSVC()\n",
    "modell.fit(X_train, y_train)\n",
    "y_pred2 = modell.predict(X_test)\n",
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pred2))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred2, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###############使用随机森林预测##############\n",
      "Testing accuracy 0.861\n"
     ]
    }
   ],
   "source": [
    "print(\"###############使用随机森林预测##############\")\n",
    "rfc = RandomForestClassifier(n_estimators=200, max_depth=4, random_state=0,n_jobs=4).fit(X_train, y_train)\n",
    "y_pre_rfc = rfc.predict(X_test)\n",
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pre_rfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "mlp = MLPClassifier().fit(X_train, y_train)\n",
    "y_pre_mlp = mlp.predict(X_test)\n",
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pre_mlp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8925\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgdc = SGDClassifier()\n",
    "sgdc.fit(X_train, y_train)\n",
    "sgdc_predict_y = sgdc.predict(X_test)\n",
    "sgdr = accuracy_score(y_test, sgdc_predict_y)\n",
    "print(sgdr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}